import argparse

parser = argparse.ArgumentParser(description='Q-Learner')
sql_args = parser.add_argument_group('SQL Monitor')
sql_args.add_argument('--bypass_sql', action='store_const', const=True, default=False, help='do not send sql')
sql_args.add_argument('--stat_host', default="192.168.23.44", help='hostname of postgres db')
sql_args.add_argument('--stat_db', default="vinci", help='postgres db name')
sql_args.add_argument('--stat_port', default=5432, type=int, help='port to postgres db')

harness_args = parser.add_argument_group('Harness')
harness_args.add_argument('--vis', action='store_const', const=True, default=False, help='show visualization')
harness_args.add_argument('--name', default="State Predictor", help='Name associated with experiment')
harness_args.add_argument('--evaluate_episode_frequency', default=100, type=int, help='evaluate every n episodes')
harness_args.add_argument('--save_tick_frequency', default=-1, type=int, help='save every n frames')
harness_args.add_argument('--save_episode_frequency', default=-1, type=int, help='save every n episodes')
harness_args.add_argument('--console_tick_frequency', default=100, type=int, help='print to screen every n frames')
harness_args.add_argument('--max_episodes', default=-1, type=int, help='train for n episodes (-1 is infinite)')
harness_args.add_argument('--max_ticks', default=100000, type=int, help='maximum ticks allowed per episode (-1 is infinite)')
harness_args.add_argument('--verbose', action='store_const', const=True, default=False, help='print to screen during training')
harness_args.add_argument('--evaluation_repetition', default=5, type=int, help='number of evaluations to average')
harness_args.add_argument('--deterministic', action='store_const', const=True, default=False, help='set random seeds when appropriate')
harness_args.add_argument('--random_seed', default=42, type=int, help='apply the weights training to target weights every n callstrains')
harness_args.add_argument('--load_checkpoint', action='store_const', const=True, default=False, help='load network and agent')
harness_args.add_argument('--death_ends_episode', action='store_const', const=True, default=False, help='load network and agent')
harness_args.add_argument('--max_initial_noop', default=30, type=int, help='randomize initial conditions with some noops')
harness_args.add_argument('--negative_reward_on_death', action='store_const', const=True, default=False, help='load network and agent')

world_args = parser.add_argument_group('world')
world_args.add_argument('--frame_skip', default=4, type=int, help='repeat actions for n frames')
world_args.add_argument('--world', default="ale", help='"ale" or "pixels"')
world_args.add_argument('--rom', default="breakout", help='filename in /worlds/ALE/roms to run')

agent_args = parser.add_argument_group('Agent')
agent_args.add_argument('--short_term_memory', default=4, type=int, help='the number of frames in phi')
agent_args.add_argument('--long_term_memory', default=10000, type=int, help='the maximum number of episodes')
agent_args.add_argument('--replay_memory_maxlen', default=1000000, type=int, help='maximum number of frames')
agent_args.add_argument('--clear_priority_frequency', default=0, type=int, help='how often to reset priorities')
agent_args.add_argument('--batch_size', default=32, type=int, help='the batch size passed to the network')
agent_args.add_argument('--burn_in', default=1000, type=int, help='the number of frames to collect before begining training')
agent_args.add_argument('--resize_width', default=84, type=int, help='the width of the input to the network')
agent_args.add_argument('--resize_height', default=84, type=int, help='the height of the input to the network')
agent_args.add_argument('--resize_method', default="crop", type=str, help='scale or crop')
agent_args.add_argument('--prioritization_type', default="uniform", help='uniform, h0, h1, or h2')
agent_args.add_argument('--exploration_epsilon_start', default=1.0, type=float, help='the starting exploration epsilon')
agent_args.add_argument('--exploration_epsilon_end', default=.1, type=float, help='the minimum exploration epsilon')
agent_args.add_argument('--exploration_epsilon_testing', default=.05, type=float, help='the exploration epsilon used during evaluations')
agent_args.add_argument('--priority_epsilon', default=.05, type=float, help='the epsilon associated with h2 priority')
agent_args.add_argument('--exploration_epsilon_decay', default=1000000, type=int, help='over how many calls to train should epsilon decay')
agent_args.add_argument('--training_iterations', default=1, type=float, help='number of times to train per frame')
agent_args.add_argument('--training_frequency', default=1, type=float, help='train every n frames')
agent_args.add_argument('--use_after_state', action='store_const', const=True, default=False, help='use the after state in memory experiences')

network_args = parser.add_argument_group('Network')
network_args.add_argument('--accumulator', default="mean", type=str, help='mean or sum')
network_args.add_argument('--discount', default=.95, type=float, help='gamma, the discount rate')
network_args.add_argument('--learning_rate_start', default=.0002, type=float, help='the learning rate')
network_args.add_argument('--learning_rate_end', default=.0002, type=float, help='the learning rate')
network_args.add_argument('--learning_rate_decay', default=100000, type=float, help='the learning rate')
network_args.add_argument('--rms_eps', default=1e-6, type=float, help='the epsilon for rmsprop')
network_args.add_argument('--rms_decay', default=.99, type=float, help='the epsilon for rmsprop')
network_args.add_argument('--network_type', default="baseline", help='baseline, baseline_two, constrained, deep or shallow')
network_args.add_argument('--clip_delta', action='store_const', const=True, default=False, help='use the fancy clipping method')
network_args.add_argument('--clip_delta_value', action='store_const', const=True, default=False, help='use the not fancy clipping method')
network_args.add_argument('--copy_frequency', default=10000, type=int, help='apply the weights training to target weights every n callstrains')
network_args.add_argument('--lookahead', default=5, type=int, help='the number of frames to look ahead when constraining')
network_args.add_argument('--constrained_lambda', default=1.0, type=float, help='the lambda used for constrained networks (ignored if network_type is not constrained)')
network_args.add_argument('--constrained_use_priorities', action='store_const', const=True, default=False, help='use priorities if network_type is constrained')
network_args.add_argument('--weight_initialization_stdev', default=0.01, type=float, help='the random normal stdev for weight initialization')
network_args.add_argument('--use_nature_values', action='store_const', const=True, default=False, help='set all parameters to nature paper values')
network_args.add_argument('--m3', action='store_const', const=True, default=False, help='devsisters m3 model')
network_args.add_argument('--m4', action='store_const', const=True, default=False, help='devsisters m4 model')